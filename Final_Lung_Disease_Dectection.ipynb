{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/username/lung-disease-detection/blob/main/lung_disease_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" width=\"140\" height=\"30\"/></a>\n",
        "</p>\n",
        "<a href=\"https://www.python.org/ftp/python/3.11.0/python-3.11.0-amd64.exe\" target=\"_parent\"><img src=\"https://www.python.org/static/community_logos/python-logo-generic.svg\" alt=\"Python Logo\" width=\"145\" height=\"45\"/></a>\n",
        "</br>\n",
        "<a href=\"https://github.com/VVBK24\" target=\"_parent\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/29/GitHub_logo_2013.svg/960px-GitHub_logo_2013.svg.png\" alt=\"Linked in\" width=\"130\" height=\"34\"/></a></br>\n"
      ],
      "metadata": {
        "id": "gd_3MU42aPP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lung Disease Detection Using Deep Learning\n",
        "\n",
        "This notebook demonstrates how to load and use the pre-trained lung disease detection model in Google Colab.\n",
        "\n",
        "The model can:\n",
        "1. Classify images into three categories: Normal, Pneumonia, and Lung Cancer\n",
        "2. Determine pneumonia or normal\n",
        "3. Classify cancer subtypes (Adenocarcinoma, Large Cell Carcinoma, Squamous Cell Carcinoma) when applicable"
      ],
      "metadata": {
        "id": "Els2JXLBa60h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "First, let's install the required dependencies.\n",
        "Such as tensorflow==2.12.0 numpy<2.0.0 matplotlib opencv-python h5py pillow"
      ],
      "metadata": {
        "id": "D9eZfVJ2bF3P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGlSp4VRaN5N"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.12.0 numpy<2.0.0 matplotlib opencv-python h5py pillow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture\n",
        "\n",
        "The lung disease detection model uses a multimodal approach combining four different architectures:\n",
        "\n",
        "- **VGG16**: Specializes in detailed feature extraction for X-ray images\n",
        "- **MobileNetV2**: Specializes in efficient X-ray image classification\n",
        "- **ResNet50**: Specializes in deep feature extraction for CT scans\n",
        "- **EfficientNetB0**: Specializes in efficient CT scan classification\n",
        "\n",
        "The features from all four models are combined to provide a comprehensive analysis of lung images, whether they're X-rays or CT scans."
      ],
      "metadata": {
        "id": "PAnbWzOLbS7I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the Model\n",
        "\n",
        "You can either upload the model directly to Colab or download it from a cloud\n",
        "storage service like Google Drive."
      ],
      "metadata": {
        "id": "pYIeXuS_bZI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests tqdm"
      ],
      "metadata": {
        "id": "Ich4YjkcbPpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vw2msAxVbqd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/dataset.zip"
      ],
      "metadata": {
        "id": "XjyVNp7mbs00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions\n",
        "\n",
        "Let's define helper functions for image preprocessing and prediction."
      ],
      "metadata": {
        "id": "Cm_mwhBXbpJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python\n",
        "!pip install pillow\n",
        "!pip install matplotlib\n",
        "!pip install keras\n",
        "!pip install h5py\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "APeX4bvybyj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. **Typical Dataset Structure for CT and X-ray Lung Disease Classification Assuming your goal is to classify:**\n",
        "\n",
        "**CT Scans into**:  ['Adenocarcinoma', 'Large Cell Carcinoma', 'Squamous Cell Carcinoma', 'normal']\n",
        "\n",
        "**X-ray Images into**:  ['pneumonia', 'normal']\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# Structure\n",
        "\n",
        "├── ct/\n",
        "│   ├── adenocarcinoma/\n",
        "│   │   ├── img1.png\n",
        "│   │   ├── img2.png\n",
        "│   │   └── ...\n",
        "│   ├── large_cell_carcinoma/\n",
        "│   │   ├── img1.png\n",
        "│   │   └── ...\n",
        "│   ├── squamous_cell_carcinoma/\n",
        "│   │   ├── img1.png\n",
        "│   │   └── ...\n",
        "│   └── normal/\n",
        "│       ├── img1.png\n",
        "│       └── ...\n",
        "│\n",
        "├── xray/\n",
        "│   ├── pneumonia/\n",
        "│   │   ├── img1.png\n",
        "│   │   └── ...\n",
        "│   └── normal/\n",
        "│       ├── img1.png\n",
        "│       └── ...\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dj7HQBY1b6xK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Split Folders** (Optional)\n",
        "\n",
        "> \"Which i did\"\n",
        "\n",
        "If you want to include train/test/val splits, structure it like this:\n",
        "#  \n",
        "```\n",
        "dataset/\n",
        "├── train/\n",
        "│   ├── ct/\n",
        "│   │   ├── adenocarcinoma/\n",
        "│   │   └── ...\n",
        "│   ├── xray/\n",
        "│   │   └── pneumonia/\n",
        "│   │   └── normal/\n",
        "│\n",
        "├── val/\n",
        "│   └── ...  # similar to train\n",
        "├── test/\n",
        "│   \n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "hn0Vl2hNcyzp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**for 1st \"Typical Dataset Structure\"**"
      ],
      "metadata": {
        "id": "5JGvc58gdhaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import EfficientNetB0, ResNet50, MobileNetV2, VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "\n",
        "# Suppress TensorFlow warnings (optional)\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Set to '0' for full logs\n",
        "\n",
        "# Enable GPU memory growth (safe multi-model training)\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"✅ GPU is available and memory growth is set!\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"❌ Error setting GPU memory growth: {e}\")\n",
        "else:\n",
        "    print(\"⚠️ GPU not available. Training will use CPU.\")\n",
        "\n",
        "# Paths and constants\n",
        "train_dir = 'dataset/train/'\n",
        "val_dir = 'dataset/val/'\n",
        "img_size = 224\n",
        "batch_size = 32\n",
        "\n",
        "# Image Generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# X-ray datasets (binary classification)\n",
        "train_xray = train_datagen.flow_from_directory(\n",
        "    os.path.join(train_dir, 'xray'),\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "val_xray = val_datagen.flow_from_directory(\n",
        "    os.path.join(val_dir, 'xray'),\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# CT scan datasets (4-class classification)\n",
        "train_ct = train_datagen.flow_from_directory(\n",
        "    os.path.join(train_dir, 'ct'),\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "val_ct = val_datagen.flow_from_directory(\n",
        "    os.path.join(val_dir, 'ct'),\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Model builder\n",
        "def build_model(base_model, input_shape=(224, 224, 3), classes=2):\n",
        "    base = base_model(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    base.trainable = False\n",
        "    x = base.output\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    if classes == 2:\n",
        "        out = layers.Dense(1, activation='sigmoid')(x)\n",
        "    else:\n",
        "        out = layers.Dense(classes, activation='softmax')(x)\n",
        "    return models.Model(inputs=base.input, outputs=out)\n",
        "\n",
        "# Build models\n",
        "xray_mobilenetv2 = build_model(MobileNetV2, classes=2)\n",
        "xray_vgg16 = build_model(VGG16, classes=2)\n",
        "ct_efficientnetb0 = build_model(EfficientNetB0, classes=4)\n",
        "ct_resnet50 = build_model(ResNet50, classes=4)\n",
        "\n",
        "# Compile models\n",
        "xray_mobilenetv2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "xray_vgg16.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "ct_efficientnetb0.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "ct_resnet50.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Checkpoints\n",
        "callbacks = {\n",
        "    'xray_mobilenetv2': ModelCheckpoint('xray_mobilenetv2.h5', save_best_only=True),\n",
        "    'xray_vgg16': ModelCheckpoint('xray_vgg16.h5', save_best_only=True),\n",
        "    'ct_efficientnetb0': ModelCheckpoint('ct_efficientnetb0.h5', save_best_only=True),\n",
        "    'ct_resnet50': ModelCheckpoint('ct_resnet50.h5', save_best_only=True),\n",
        "}\n",
        "\n",
        "# Train models\n",
        "print(\"\\n🔧 Training xray_mobilenetv2...\")\n",
        "xray_mobilenetv2.fit(train_xray, epochs=10, validation_data=val_xray, callbacks=[callbacks['xray_mobilenetv2']])\n",
        "\n",
        "print(\"\\n🔧 Training xray_vgg16...\")\n",
        "xray_vgg16.fit(train_xray, epochs=10, validation_data=val_xray, callbacks=[callbacks['xray_vgg16']])\n",
        "\n",
        "print(\"\\n🔧 Training ct_efficientnetb0...\")\n",
        "ct_efficientnetb0.fit(train_ct, epochs=10, validation_data=val_ct, callbacks=[callbacks['ct_efficientnetb0']])\n",
        "\n",
        "print(\"\\n🔧 Training ct_resnet50...\")\n",
        "ct_resnet50.fit(train_ct, epochs=10, validation_data=val_ct, callbacks=[callbacks['ct_resnet50']])\n",
        "\n",
        "print(\"\\n✅ All 4 models trained and saved using GPU (if available)!\")"
      ],
      "metadata": {
        "id": "VJUe_DaldgOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Save the model to the drive**"
      ],
      "metadata": {
        "id": "vSTBPt7leCtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the source and destination directories\n",
        "source_models = ['xray_mobilenetv2.h5', 'xray_vgg16.h5', 'ct_efficientnetb0.h5', 'ct_resnet50.h5']\n",
        "destination_dir = '/content/drive/MyDrive/trained_models2'  # Replace with your desired destination\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "!mkdir -p \"{destination_dir}\"\n",
        "\n",
        "# Copy the model files to Google Drive\n",
        "for model_file in source_models:\n",
        "  if os.path.exists(model_file):\n",
        "    shutil.copy(model_file, destination_dir)\n",
        "    print(f\"✅ '{model_file}' copied to Google Drive.\")\n",
        "  else:\n",
        "    print(f\"⚠️ '{model_file}' not found. Skipping...\")"
      ],
      "metadata": {
        "id": "xfMmzDRYeCMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> for the 2nd structure\n",
        "\n"
      ],
      "metadata": {
        "id": "a6aHnONcdJgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2, VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import os\n",
        "\n",
        "# ✅ Enable GPU memory growth\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"✅ GPU memory growth enabled!\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"❌ GPU Error: {e}\")\n",
        "else:\n",
        "    print(\"⚠️ GPU not available. Using CPU.\")\n",
        "\n",
        "# 📁 Paths for X-ray data\n",
        "train_path = 'dataset/train/xray/'\n",
        "val_path = 'dataset/val/xray/'\n",
        "\n",
        "# 🔄 Data generators\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=20,\n",
        "                                   zoom_range=0.2,\n",
        "                                   width_shift_range=0.1,\n",
        "                                   height_shift_range=0.1,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(train_path,\n",
        "                                              target_size=(224, 224),\n",
        "                                              batch_size=32,\n",
        "                                              class_mode='categorical',\n",
        "                                              shuffle=True)\n",
        "\n",
        "val_gen = val_datagen.flow_from_directory(val_path,\n",
        "                                          target_size=(224, 224),\n",
        "                                          batch_size=32,\n",
        "                                          class_mode='categorical',\n",
        "                                          shuffle=False)\n",
        "\n",
        "# 🧠 Model builder\n",
        "def build_model(base_model, num_classes=2):\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "    return Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# 🔨 MobileNetV2\n",
        "mobile_base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "mobile_model = build_model(mobile_base, num_classes=train_gen.num_classes)\n",
        "mobile_model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 🔨 VGG16\n",
        "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "vgg_model = build_model(vgg_base, num_classes=train_gen.num_classes)\n",
        "vgg_model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 🚀 Train MobileNetV2\n",
        "print(\"\\n🚀 Training MobileNetV2...\")\n",
        "mobile_model.fit(train_gen, validation_data=val_gen, epochs=10)\n",
        "\n",
        "# 🚀 Train VGG16\n",
        "print(\"\\n🚀 Training VGG16...\")\n",
        "vgg_model.fit(train_gen, validation_data=val_gen, epochs=10)\n",
        "\n",
        "# 💾 Save models\n",
        "mobile_model.save('xray_mobilenetv2.h5')\n",
        "vgg_model.save('xray_vgg16.h5')"
      ],
      "metadata": {
        "id": "xHQ3U-s4b0v8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 📦 Imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50, EfficientNetV2S\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import os\n",
        "\n",
        "# 🖥️ Suppress warnings & enable GPU memory growth\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"✅ GPU is available and memory growth is set!\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"❌ Error setting GPU memory growth: {e}\")\n",
        "else:\n",
        "    print(\"⚠️ GPU not available. Training will use CPU.\")\n",
        "\n",
        "# 📁 Data Paths\n",
        "train_path = 'dataset/train/ct'\n",
        "val_path = 'dataset/val/ct'\n",
        "\n",
        "# 🔄 Data Generators\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20,\n",
        "                                   width_shift_range=0.2, height_shift_range=0.2,\n",
        "                                   shear_range=0.2, zoom_range=0.2,\n",
        "                                   horizontal_flip=True, fill_mode='nearest')\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(train_path, target_size=(224, 224),\n",
        "                                              batch_size=32, class_mode='categorical')\n",
        "\n",
        "val_gen = val_datagen.flow_from_directory(val_path, target_size=(224, 224),\n",
        "                                          batch_size=32, class_mode='categorical')\n",
        "\n",
        "# 🧠 Model Builder\n",
        "def build_model(base_model, num_classes=4):\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    output = Dense(num_classes, activation='softmax')(x)\n",
        "    return Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# 🔨 ResNet50\n",
        "resnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "resnet_model = build_model(resnet_base, num_classes=train_gen.num_classes)\n",
        "resnet_model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 🔨 EfficientNetV2S (TensorFlow Built-in)\n",
        "eff_base = EfficientNetV2S(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "eff_model = build_model(eff_base, num_classes=train_gen.num_classes)\n",
        "eff_model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 🚀 Train both models\n",
        "resnet_model.fit(train_gen, validation_data=val_gen, epochs=10)\n",
        "eff_model.fit(train_gen, validation_data=val_gen, epochs=10)\n",
        "\n",
        "# 💾 Save models\n",
        "resnet_model.save('ct_resnet50.h5')\n",
        "eff_model.save('ct_efficientnetv2s.h5')"
      ],
      "metadata": {
        "id": "yzGeow2Je98E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Save the models to Drive**"
      ],
      "metadata": {
        "id": "GPU1UHrmm37n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the source and destination directories\n",
        "source_models = ['xray_mobilenetv2.h5', 'xray_vgg16.h5', 'ct_efficientnetv2s.h5', 'ct_resnet50.h5']\n",
        "destination_dir = '/content/drive/MyDrive/trained_models2'  # Replace with your desired destination\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "!mkdir -p \"{destination_dir}\"\n",
        "\n",
        "# Copy the model files to Google Drive\n",
        "for model_file in source_models:\n",
        "  if os.path.exists(model_file):\n",
        "    shutil.copy(model_file, destination_dir)\n",
        "    print(f\"✅ '{model_file}' copied to Google Drive.\")\n",
        "  else:\n",
        "    print(f\"⚠️ '{model_file}' not found. Skipping...\")"
      ],
      "metadata": {
        "id": "guvgCtkNe1q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Checking if GPU is being used**\n",
        "and also checking for which version of the tensorflow"
      ],
      "metadata": {
        "id": "U2kM7vJafhuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# List devices\n",
        "print(\"\\n🧠 TensorFlow version:\", tf.__version__)\n",
        "print(\"📦 GPU devices detected:\", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "# Check if GPU is being used\n",
        "from tensorflow.python.client import device_lib\n",
        "print(\"\\n💻 Available devices:\")\n",
        "print(device_lib.list_local_devices())"
      ],
      "metadata": {
        "id": "KMAcjL0wflov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image Classification**\n",
        "Before we move to the model testing we need to create 1 sperate model to identify if the model is ct scan or xray  "
      ],
      "metadata": {
        "id": "TjHWsv-cgVLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 1: Setup\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import os\n",
        "\n",
        "print(\"✅ TensorFlow Version:\", tf.__version__)\n",
        "\n",
        "train_dir = 'dataset/train'\n",
        "val_dir = 'dataset/val'\n",
        "\n",
        "# ✅ Step 4: Preprocessing\n",
        "image_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "datagen_train = ImageDataGenerator(rescale=1./255)\n",
        "datagen_val = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# ✅ Step 5: Load CT and X-ray folders as classes\n",
        "train_generator = datagen_train.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',  # 'ct' vs 'xray'\n",
        "    classes=['ct', 'xray']\n",
        ")\n",
        "\n",
        "val_generator = datagen_val.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    classes=['ct', 'xray']\n",
        ")\n",
        "\n",
        "# ✅ Step 6: Define the model\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# ✅ Step 7: Compile\n",
        "model.compile(optimizer=Adam(1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# ✅ Step 8: Train\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "# ✅ Step 9: Save the model\n",
        "model.save(\"ct_vs_xray_classifier.h5\")\n",
        "print(\"✅ Model saved as ct_vs_xray_classifier.h5\")"
      ],
      "metadata": {
        "id": "D0SUP3NAgzZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook demonstrated how to use the pre-trained lung disease detection model to analyze X-ray and CT scan images. The model can classify images into different disease categories, determine pneumonia severity, and identify cancer subtypes.\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. Try with your own medical images\n",
        "2. Fine-tune the model on your specific dataset\n",
        "3. Experiment with different visualization techniques\n",
        "4. Integrate with other medical diagnostic systems"
      ],
      "metadata": {
        "id": "bGJBvOg6f083"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "base_path = '/content/drive/MyDrive/trained_models/'\n",
        "\n",
        "# ✅ Paths for the models\n",
        "ct_efficientnetv2s_path = base_path + 'ct_efficientnetb0.h5'\n",
        "ct_resnet50_path = base_path + 'ct_resnet50.h5'\n",
        "# xray_mobilenetv2_path = base_path + 'xray_mobilenetv2.h5'\n",
        "# xray_vgg16_path = base_path + 'xray_vgg16.h5'\n",
        "\n",
        "\n",
        "# ✅ Load all models\n",
        "scan_type_model = load_model('ct_vs_xray_classifier.h5')\n",
        "ct_efficientnetv2s = load_model(ct_efficientnetv2s_path)\n",
        "ct_resnet50 = load_model(ct_resnet50_path)\n",
        "xray_mobilenetv2 = load_model('xray_mobilenetV2.h5')\n",
        "xray_vgg16 = load_model('xray_vgg16.h5')\n",
        "\n",
        "# ✅ Class labels\n",
        "ct_classes = ['Adenocarcinoma', 'Large Cell Carcinoma', 'Squamous Cell Carcinoma', 'normal']\n",
        "xray_classes = ['pneumonia', 'normal']\n",
        "\n",
        "def predict_scan_and_disease(img_path):\n",
        "    try:\n",
        "        # Load & preprocess image\n",
        "        img = image.load_img(img_path, target_size=(224, 224))\n",
        "        img_array = image.img_to_array(img) / 255.0\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "        # 🧠 Step 1: Predict scan type\n",
        "        scan_pred = scan_type_model.predict(img_array)[0][0]\n",
        "        scan_type = \"ct\" if scan_pred < 0.5 else \"xray\"\n",
        "        print(f\"🧪 Predicted Scan Type: {scan_type.upper()}\")\n",
        "\n",
        "        # 🧠 Step 2: Print all model results\n",
        "        print(\"\\n🧠 All Model Predictions:\")\n",
        "\n",
        "        # For CT scans\n",
        "        if scan_type == \"ct\":\n",
        "            print(\"📡 Using CT Models:\")\n",
        "            ct_resnet50_pred = ct_resnet50.predict(img_array)\n",
        "            print(f\"ResNet50 Prediction: {ct_classes[np.argmax(ct_resnet50_pred)]} (Raw: {ct_resnet50_pred})\")\n",
        "\n",
        "            ct_efficientnetv2s_pred = ct_efficientnetv2s.predict(img_array)\n",
        "            print(f\"EfficientNetV2s Prediction: {ct_classes[np.argmax(ct_efficientnetv2s_pred)]} (Raw: {ct_efficientnetv2s_pred})\")\n",
        "\n",
        "        # For X-ray scans\n",
        "        else:\n",
        "            print(\"📡 Using X-ray Models:\")\n",
        "            xray_mobilenetv2_pred = xray_mobilenetv2.predict(img_array)\n",
        "            print(f\"MobileNetV2 Prediction: {xray_classes[np.argmax(xray_mobilenetv2_pred)]} (Raw: {xray_mobilenetv2_pred})\")\n",
        "\n",
        "            xray_vgg16_pred = xray_vgg16.predict(img_array)\n",
        "            print(f\"VGG16 Prediction: {xray_classes[np.argmax(xray_vgg16_pred)]} (Raw: {xray_vgg16_pred})\")\n",
        "\n",
        "        # Return the best prediction\n",
        "        if scan_type == \"ct\":\n",
        "            disease_pred = ct_resnet50.predict(img_array)  # Default to ResNet50 for CT\n",
        "            disease_label = ct_classes[np.argmax(disease_pred)]\n",
        "        else:\n",
        "            disease_pred = xray_mobilenetv2.predict(img_array)  # Default to MobileNetV2 for X-ray\n",
        "            disease_label = xray_classes[np.argmax(disease_pred)]\n",
        "\n",
        "        print(f\"\\n💉 Final Predicted Disease: {disease_label}\")\n",
        "        return scan_type, disease_label\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error: {e}\")\n",
        "\n",
        "# ✅ Upload image function (using Google Colab file upload)\n",
        "def upload_image():\n",
        "    uploaded = files.upload()  # Upload files using Google Colab\n",
        "    if uploaded:\n",
        "        img_path = list(uploaded.keys())[0]  # Get the path of the uploaded image\n",
        "        print(f\"Image uploaded: {img_path}\")\n",
        "        return img_path\n",
        "    else:\n",
        "        print(\"No file selected.\")\n",
        "        return None\n",
        "\n",
        "# Example: Upload an image and predict\n",
        "img_path = upload_image()\n",
        "if img_path:\n",
        "    scan_type, disease_label = predict_scan_and_disease(img_path)"
      ],
      "metadata": {
        "id": "UesRfWwqf0uN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}